<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>📈 Theory overview &mdash; PUNCC 0.7.4 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/_static/theme_overrides.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="🖼️ Plotting" href="plotting.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            PUNCC
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">🚀 Quickstart</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#conformal-regression">📈 Conformal Regression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#diabetes-dataset">💾 Diabetes Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#prediction-model">🔮 Prediction model</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#conformal-prediction">⚙️ Conformal prediction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#conformal-classification">📊 Conformal Classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#mnist-dataset">💾 MNIST Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#id1">🔮 Prediction Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#id2">⚙️ Conformal prediction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#conformal-anomaly-detection">🚩 Conformal Anomaly Detection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#two-moons-dataset">💾 Two moons Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#anomaly-detection-model">🔮 Anomaly detection model</a></li>
<li class="toctree-l3"><a class="reference internal" href="getting_started.html#id3">⚙️ Conformal Anomaly Detection</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="regression.html">📈 Regression</a><ul>
<li class="toctree-l2"><a class="reference internal" href="regression.html#deel.puncc.regression.SplitCP"><code class="docutils literal notranslate"><span class="pre">SplitCP</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.SplitCP.fit"><code class="docutils literal notranslate"><span class="pre">SplitCP.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.SplitCP.get_nonconformity_scores"><code class="docutils literal notranslate"><span class="pre">SplitCP.get_nonconformity_scores()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.SplitCP.predict"><code class="docutils literal notranslate"><span class="pre">SplitCP.predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="regression.html#deel.puncc.regression.LocallyAdaptiveCP"><code class="docutils literal notranslate"><span class="pre">LocallyAdaptiveCP</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.LocallyAdaptiveCP.fit"><code class="docutils literal notranslate"><span class="pre">LocallyAdaptiveCP.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.LocallyAdaptiveCP.get_nonconformity_scores"><code class="docutils literal notranslate"><span class="pre">LocallyAdaptiveCP.get_nonconformity_scores()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.LocallyAdaptiveCP.predict"><code class="docutils literal notranslate"><span class="pre">LocallyAdaptiveCP.predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="regression.html#deel.puncc.regression.CQR"><code class="docutils literal notranslate"><span class="pre">CQR</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.CQR.fit"><code class="docutils literal notranslate"><span class="pre">CQR.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.CQR.get_nonconformity_scores"><code class="docutils literal notranslate"><span class="pre">CQR.get_nonconformity_scores()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.CQR.predict"><code class="docutils literal notranslate"><span class="pre">CQR.predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="regression.html#deel.puncc.regression.CVPlus"><code class="docutils literal notranslate"><span class="pre">CVPlus</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.CVPlus.fit"><code class="docutils literal notranslate"><span class="pre">CVPlus.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.CVPlus.get_nonconformity_scores"><code class="docutils literal notranslate"><span class="pre">CVPlus.get_nonconformity_scores()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.CVPlus.predict"><code class="docutils literal notranslate"><span class="pre">CVPlus.predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="regression.html#deel.puncc.regression.EnbPI"><code class="docutils literal notranslate"><span class="pre">EnbPI</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.EnbPI.fit"><code class="docutils literal notranslate"><span class="pre">EnbPI.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.EnbPI.predict"><code class="docutils literal notranslate"><span class="pre">EnbPI.predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="regression.html#deel.puncc.regression.AdaptiveEnbPI"><code class="docutils literal notranslate"><span class="pre">AdaptiveEnbPI</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.AdaptiveEnbPI.fit"><code class="docutils literal notranslate"><span class="pre">AdaptiveEnbPI.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="regression.html#deel.puncc.regression.AdaptiveEnbPI.predict"><code class="docutils literal notranslate"><span class="pre">AdaptiveEnbPI.predict()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">📊 Classification</a><ul>
<li class="toctree-l2"><a class="reference internal" href="classification.html#deel.puncc.classification.RAPS"><code class="docutils literal notranslate"><span class="pre">RAPS</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="classification.html#deel.puncc.classification.RAPS.fit"><code class="docutils literal notranslate"><span class="pre">RAPS.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="classification.html#deel.puncc.classification.RAPS.predict"><code class="docutils literal notranslate"><span class="pre">RAPS.predict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="classification.html#deel.puncc.classification.APS"><code class="docutils literal notranslate"><span class="pre">APS</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="classification.html#deel.puncc.classification.APS.fit"><code class="docutils literal notranslate"><span class="pre">APS.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="classification.html#deel.puncc.classification.APS.predict"><code class="docutils literal notranslate"><span class="pre">APS.predict()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="anomaly_detection.html">🚩 Anomaly detection</a><ul>
<li class="toctree-l2"><a class="reference internal" href="anomaly_detection.html#deel.puncc.anomaly_detection.SplitCAD"><code class="docutils literal notranslate"><span class="pre">SplitCAD</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="anomaly_detection.html#deel.puncc.anomaly_detection.SplitCAD.fit"><code class="docutils literal notranslate"><span class="pre">SplitCAD.fit()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="anomaly_detection.html#deel.puncc.anomaly_detection.SplitCAD.predict"><code class="docutils literal notranslate"><span class="pre">SplitCAD.predict()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">💻 API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api.html#api-s-modules">API’s Modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="conformalization.html">Conformalization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="conformalization.html#conformalization.ConformalPredictor"><code class="docutils literal notranslate"><span class="pre">ConformalPredictor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="conformalization.html#conformalization.CrossValCpAggregator"><code class="docutils literal notranslate"><span class="pre">CrossValCpAggregator</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="prediction.html">Prediction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="prediction.html#prediction.BasePredictor"><code class="docutils literal notranslate"><span class="pre">BasePredictor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="prediction.html#prediction.DualPredictor"><code class="docutils literal notranslate"><span class="pre">DualPredictor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="prediction.html#prediction.MeanVarPredictor"><code class="docutils literal notranslate"><span class="pre">MeanVarPredictor</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="calibration.html">Calibration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="calibration.html#calibration.BaseCalibrator"><code class="docutils literal notranslate"><span class="pre">BaseCalibrator</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="calibration.html#calibration.CvPlusCalibrator"><code class="docutils literal notranslate"><span class="pre">CvPlusCalibrator</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="calibration.html#calibration.ScoreCalibrator"><code class="docutils literal notranslate"><span class="pre">ScoreCalibrator</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="splitting.html">Splitting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="splitting.html#splitting.BaseSplitter"><code class="docutils literal notranslate"><span class="pre">BaseSplitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="splitting.html#splitting.IdSplitter"><code class="docutils literal notranslate"><span class="pre">IdSplitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="splitting.html#splitting.RandomSplitter"><code class="docutils literal notranslate"><span class="pre">RandomSplitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="splitting.html#splitting.KFoldSplitter"><code class="docutils literal notranslate"><span class="pre">KFoldSplitter</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="utils.html">Utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="utils.html#deel.puncc.api.utils.alpha_calib_check"><code class="docutils literal notranslate"><span class="pre">alpha_calib_check()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="utils.html#deel.puncc.api.utils.quantile"><code class="docutils literal notranslate"><span class="pre">quantile()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nonconformity_scores.html">Nonconformity scores</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nonconformity_scores.html#nonconformity_scores.cqr_score"><code class="docutils literal notranslate"><span class="pre">cqr_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="nonconformity_scores.html#nonconformity_scores.mad"><code class="docutils literal notranslate"><span class="pre">mad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="nonconformity_scores.html#nonconformity_scores.raps_score"><code class="docutils literal notranslate"><span class="pre">raps_score()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="nonconformity_scores.html#nonconformity_scores.raps_score_builder"><code class="docutils literal notranslate"><span class="pre">raps_score_builder()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="nonconformity_scores.html#nonconformity_scores.scaled_mad"><code class="docutils literal notranslate"><span class="pre">scaled_mad()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="prediction_sets.html">Prediction sets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="prediction_sets.html#prediction_sets.constant_interval"><code class="docutils literal notranslate"><span class="pre">constant_interval()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="prediction_sets.html#prediction_sets.cqr_interval"><code class="docutils literal notranslate"><span class="pre">cqr_interval()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="prediction_sets.html#prediction_sets.raps_set"><code class="docutils literal notranslate"><span class="pre">raps_set()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="prediction_sets.html#prediction_sets.raps_set_builder"><code class="docutils literal notranslate"><span class="pre">raps_set_builder()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="prediction_sets.html#prediction_sets.scaled_interval"><code class="docutils literal notranslate"><span class="pre">scaled_interval()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api.html#conformalpredictor">ConformalPredictor</a></li>
<li class="toctree-l3"><a class="reference internal" href="api.html#predictor">Predictor</a></li>
<li class="toctree-l3"><a class="reference internal" href="api.html#calibrator">Calibrator</a></li>
<li class="toctree-l3"><a class="reference internal" href="api.html#splitter">Splitter</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">📏 Metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="metrics.html#metrics.classification_mean_coverage"><code class="docutils literal notranslate"><span class="pre">classification_mean_coverage()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html#metrics.classification_mean_size"><code class="docutils literal notranslate"><span class="pre">classification_mean_size()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html#metrics.regression_ace"><code class="docutils literal notranslate"><span class="pre">regression_ace()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html#metrics.regression_mean_coverage"><code class="docutils literal notranslate"><span class="pre">regression_mean_coverage()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html#metrics.regression_sharpness"><code class="docutils literal notranslate"><span class="pre">regression_sharpness()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="plotting.html">🖼️ Plotting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="plotting.html#plotting.plot_prediction_intervals"><code class="docutils literal notranslate"><span class="pre">plot_prediction_intervals()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">📈 Theory overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#uncertainty-quantification">Uncertainty Quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conformal-prediction">Conformal Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#conformal-regression">Conformal Regression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#split-inductive-conformal">Split (inductive) Conformal</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#locally-adaptive-conformal-regression">Locally Adaptive Conformal Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conformalized-quantile-regression-cqr">Conformalized Quantile Regression (CQR)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#cross-validation-cv-jackknife">Cross-validation+ (CV+), Jackknife+</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ensemble-batch-prediction-intervals-enbpi">Ensemble Batch Prediction Intervals (EnbPI)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#conformal-classification">Conformal Classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#adaptive-prediction-sets-aps">Adaptive Prediction Sets (APS)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#regularized-adaptive-prediction-sets-raps">Regularized Adaptive Prediction Sets (RAPS)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#conformal-anomaly-detection">Conformal Anomaly Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PUNCC</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">📈 Theory overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/theory_overview.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="theory-overview">
<span id="id1"></span><h1>📈 Theory overview<a class="headerlink" href="#theory-overview" title="Permalink to this heading"></a></h1>
<section id="uncertainty-quantification">
<h2>Uncertainty Quantification<a class="headerlink" href="#uncertainty-quantification" title="Permalink to this heading"></a></h2>
<p>In machine learning, we build predictive models from experience,
by choosing the right approach for the right problem, and from the accessible
data, via algorithms. Despite our best efforts, we can encounter some
underlying uncertainty that could stem from various sources or causes.</p>
<dl class="simple">
<dt>Typically, uncertainty in the machine learning process can be categorized into two types:</dt><dd><ul class="simple">
<li><p>Aleatoric uncertainty, also known as statistical uncertainty, which is <em>irreducible</em> as due to the intrinsic randomness of the phenomenon being modeled</p></li>
<li><p>Epistemic uncertainty, also known as systematic uncertainty, which is <em>reducible</em> through additional information, e.g. via more data or better models</p></li>
</ul>
</dd>
</dl>
<p>Depending on the application fields of machine learning models, uncertainty can have major impacts on performance and/or safety.</p>
</section>
<section id="conformal-prediction">
<h2>Conformal Prediction<a class="headerlink" href="#conformal-prediction" title="Permalink to this heading"></a></h2>
<p>Conformal Prediction (CP) is a set of <em>distribution-free</em>, <em>model-agnostic</em> and
<em>non-asymptotic</em> methods to estimate uncertainty by constructing <strong>valid</strong> <em>prediction sets</em>, i.e. with guaranteed probability of marginal coverage.</p>
<p>Given an error rate (or significance level) <span class="math notranslate nohighlight">\(\alpha \in (0,1)\)</span>, set by the user, a set of exchangeable (or more simply i.i.d.)
train data <span class="math notranslate nohighlight">\(\{ (X_i, Y_i) \}_{i=1}^{n}\)</span> and test point
<span class="math notranslate nohighlight">\((X_{new}, Y_{new})\)</span> generated for a joint distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{XY}\)</span>,
a conformal prediction procedure builds prediction sets <span class="math notranslate nohighlight">\({C}_{\alpha}(\cdot)\)</span> so that:</p>
<div class="math notranslate nohighlight">
\[\mathbb{P} \Big\{ Y_{new} \in {C}_{\alpha}\left(X_{new}\right) \Big\} \geq 1 - \alpha.\]</div>
<p>Over many calibration and test sets, <span class="math notranslate nohighlight">\({C}_{\alpha}(X_{new})\)</span> will contain
the observed values of <span class="math notranslate nohighlight">\(Y_{new}\)</span> with frequency of <em>at least</em> <span class="math notranslate nohighlight">\((1-\alpha)\)</span>.</p>
<p>Within the conformal prediction framework, the inequality above holds for any model,
any data distribution <span class="math notranslate nohighlight">\(\mathbb{P}_{XY}\)</span> and any finite sample sizes.
It is noteworthy that the coverage probability is marginalized over <span class="math notranslate nohighlight">\(X\)</span>.
Therefore, it is likely to undercover conditionally to some specific regions in the space of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Conformal prediction can act as a <em>post-processing procedure</em> to attain rigorous probability coverages,
as it can “conformalize” any existing predictor during or after training (black box predictors),
yielding marginally valid prediction sets.</p>
<p>In this page, we present the most common conformal prediction methods of the
literature used on regression and classification models. We also refer to
Angelopoulos and Bates <a class="reference internal" href="#angelopoulos2022" id="id2"><span>[Angelopoulos2022]</span></a> for a hands-on introduction to conformal prediction
and awesome conformal prediction <a class="reference external" href="https://github.com/valeman/awesome-conformal-prediction">github</a> for additional ressources.</p>
<p>In the following, let <span class="math notranslate nohighlight">\(D_{train} = {(X_i, Y_i)}_{i=1..n_{train}} \sim P_{XY}\)</span>
be the training data and <span class="math notranslate nohighlight">\(\alpha \in (0, 1)\)</span> the significance level (target maximum error rate).</p>
</section>
<section id="conformal-regression">
<h2>Conformal Regression<a class="headerlink" href="#conformal-regression" title="Permalink to this heading"></a></h2>
<section id="split-inductive-conformal">
<h3>Split (inductive) Conformal<a class="headerlink" href="#split-inductive-conformal" title="Permalink to this heading"></a></h3>
<p id="theory-splitcp">The split (also called inductive) conformal prediction <a class="reference internal" href="#papadopoulos2002" id="id3"><span>[Papadopoulos2002]</span></a> <a class="reference internal" href="#lei2018" id="id4"><span>[Lei2018]</span></a> requires a hold-out calibration
dataset <span class="math notranslate nohighlight">\(D_{calibration}\)</span> to estimate prediction errors and use them to build the prediction interval for a new sample <span class="math notranslate nohighlight">\(X_{new}\)</span>.</p>
<p>Given a prediction model <span class="math notranslate nohighlight">\(\widehat{f}\)</span> trained on <span class="math notranslate nohighlight">\(D_{train}\)</span>, the algorithm is summarized in the following:</p>
<ol class="arabic simple">
<li><p>Choose a nonconformity score <span class="math notranslate nohighlight">\(s\)</span>: <span class="math notranslate nohighlight">\(R = s(\widehat{f}(X),Y)\)</span>. For example, one can pick the mean absolute deviation <span class="math notranslate nohighlight">\(R = |\widehat{f}(X)-Y|\)</span>.</p></li>
<li><p>Compute the nonconformity scores on the calibration dataset: <span class="math notranslate nohighlight">\(\bar{R} = \{R_i\}_{}\)</span>, for <span class="math notranslate nohighlight">\(i=1,\dots,|D_{calibration}|\)</span>, where <span class="math notranslate nohighlight">\(|D_{calibration}|\)</span> is the cardinality of <span class="math notranslate nohighlight">\(D_{calibration}\)</span>.</p></li>
<li><p>Compute the error margin <span class="math notranslate nohighlight">\(\delta_{\alpha}\)</span> as the <span class="math notranslate nohighlight">\((1-\alpha)(1 + \frac{1}{| D_{calibration} |})\)</span>-th empirical quantile of <span class="math notranslate nohighlight">\(\bar{R}\)</span>.</p></li>
<li><p>Build the prediction interval <span class="math notranslate nohighlight">\(\widehat{C}_{\alpha}(X_{new}) = \Big[ \widehat{f}(X_{new}) - \delta_{\alpha}^{f} \,,\, \widehat{f}(X_{new}) + \delta_{\alpha}^{f} \Big]\)</span>.</p></li>
</ol>
<p>Note that this procedure yields a constant-width prediction interval centered on the point estimate <span class="math notranslate nohighlight">\(\widehat{f}(X_{new})\)</span>.</p>
<p>In the literature, the split conformal procedure has been combined with different nonconformity scores,
which produced several methods. Some of them are presented hereafter.</p>
<section id="locally-adaptive-conformal-regression">
<h4>Locally Adaptive Conformal Regression<a class="headerlink" href="#locally-adaptive-conformal-regression" title="Permalink to this heading"></a></h4>
<p id="theory-lacp">The locally adaptive conformal regression <a class="reference internal" href="#papadopoulos2008" id="id5"><span>[Papadopoulos2008]</span></a> relies on scaled nonconformity scores:</p>
<div class="math notranslate nohighlight">
\[R_i = \frac{|\widehat{f}(X_i) - Y_i|}{\widehat{\sigma}(X_i)},\]</div>
<p>where <span class="math notranslate nohighlight">\(\widehat{\sigma}(X_i)\)</span> is a measure of dispersion of the nonconformity scores at <span class="math notranslate nohighlight">\(X_i\)</span>.
Usually, <span class="math notranslate nohighlight">\(\widehat{\sigma}\)</span> is trained to estimate the absolute prediction
error <span class="math notranslate nohighlight">\(|\widehat{f}(X)-Y|\)</span> given <span class="math notranslate nohighlight">\(X=x\)</span>. The prediction interval is again
centered on <span class="math notranslate nohighlight">\(\widehat{f}(X_{new})\)</span> but the margins are scaled w.r.t the estimated local variability at <span class="math notranslate nohighlight">\(Y | X = X_{new}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\widehat{C}_{\alpha}(X_{new})=
\Big[ \widehat{f}(X_{new}) - \widehat{\sigma}(X_{new})\, \delta_{\alpha} \,,\, \widehat{f}(X_{new}) + \widehat{\sigma}(X_{new}) \, \delta_{\alpha} \Big].\]</div>
<p>The prediction intervals are therefore of variable width, which is more adaptive to heteroskedascity and
usually improve the conditional coverage. The price is the higher computational cost due to fitting two functions
<span class="math notranslate nohighlight">\(\widehat{f}\)</span> and <span class="math notranslate nohighlight">\(\widehat{\sigma}\)</span>, on the proper training set.</p>
</section>
<section id="conformalized-quantile-regression-cqr">
<h4>Conformalized Quantile Regression (CQR)<a class="headerlink" href="#conformalized-quantile-regression-cqr" title="Permalink to this heading"></a></h4>
<p id="theory-cqr">Split conformal prediction can be extended to <a class="reference external" href="https://en.wikipedia.org/wiki/Quantile_regression">quantile predictors</a>  <span class="math notranslate nohighlight">\(q(\cdot)\)</span>
by using the nonconformity score:</p>
<div class="math notranslate nohighlight">
\[R_i^{} = \text{max}\{ \widehat{q}_{\alpha_{lo}}(X_i) - Y_i, Y_i - \widehat{q}_{1 - \alpha_{hi}}(X_i)\},\]</div>
<p>for <span class="math notranslate nohighlight">\(i=1,\dots,|D_{calibration}|\)</span>. <span class="math notranslate nohighlight">\(\widehat{q}_{\alpha_{lo}}\)</span> and <span class="math notranslate nohighlight">\(\widehat{q}_{1-\alpha_{hi}}\)</span> are
the predictors of the <span class="math notranslate nohighlight">\(\alpha_{lo}\)</span> <em>-th</em> and <span class="math notranslate nohighlight">\((1-\alpha_{hi})\)</span> <em>-th</em> quantiles of <span class="math notranslate nohighlight">\(Y | X\)</span>, respectively.
For example, if we set <span class="math notranslate nohighlight">\(\alpha = 0.1\)</span>, we would fit two predictors <span class="math notranslate nohighlight">\(\widehat{q}_{0.05}(\cdot)\)</span> and <span class="math notranslate nohighlight">\(\widehat{q}_{0.95}(\cdot)\)</span> on training data <span class="math notranslate nohighlight">\(D_{train}\)</span> and compute the scores on <span class="math notranslate nohighlight">\(D_{calibration}\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is common to split evenly <span class="math notranslate nohighlight">\(\alpha\)</span> as: <span class="math notranslate nohighlight">\(\alpha_{lo} = \alpha_{hi}= \frac{\alpha}{2}\)</span>, but users are free to do otherwise.</p>
</div>
<p>The procedure, named <em>Conformalized Quantile Regression</em> <a class="reference internal" href="#romano2019" id="id6"><span>[Romano2019]</span></a>, yields the following prediction interval:</p>
<div class="math notranslate nohighlight">
\[\widehat{C}_{\alpha}(X_{new}) = \Big[ \widehat{q}_{\alpha_{lo}}(X_{new}) - \delta_{\alpha} \,,\, \widehat{q}_{1 - \alpha_{hi}}(X_{new}) + \delta_{\alpha} \Big].\]</div>
<p>When data are exchangeable, the correction margin <span class="math notranslate nohighlight">\(\delta_{\alpha}\)</span> guarantees finite-sample marginal coverage for the quantile predictions, and this holds also for misspecified (i.e. “bad”) predictors.</p>
<p>If the fitted <span class="math notranslate nohighlight">\(\widehat{q}_{\alpha_{lo}}\)</span> and <span class="math notranslate nohighlight">\(\widehat{q}_{1-\alpha_{hi}}\)</span> approximate (empirically) well  the conditional distribution <span class="math notranslate nohighlight">\(Y | X\)</span> of the data, we will get a small margin <span class="math notranslate nohighlight">\(\delta_{\alpha}\)</span>: this means that on average, the prediction errors on the <span class="math notranslate nohighlight">\(D_{calibration}\)</span> were small.</p>
<p>Also, if the base predictors have strong theoretical properties, our CP procedure inherits these properties of <span class="math notranslate nohighlight">\(\widehat{q}_{}(\cdot)\)</span>.
We could have an asymptotically, conditionally accurate predictor and also have a theoretically valid, distribution-free guarantee on the marginal coverage!</p>
</section>
</section>
<section id="cross-validation-cv-jackknife">
<h3>Cross-validation+ (CV+), Jackknife+<a class="headerlink" href="#cross-validation-cv-jackknife" title="Permalink to this heading"></a></h3>
<p id="theory-cvplus">The <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">leave-one-out (LOO) and the k-fold cross-validation</a> are well known schemes used to estimate regression residuals on out-of-sample data.
As shown below, one first splits the data into K partitions and then <em>holds out</em> a partition at a time to compute errors (nonconformity scores, in our case).
Following this principle, <a class="reference internal" href="#barber2021" id="id7"><span>[Barber2021]</span></a> introduced the LOO <em>jackknife+</em> (JP) and the k-fold <em>Cross-validation+</em> (CV+).
With these methods, one does <em>not need</em> a dedicated calibration set.</p>
<a class="reference internal image-reference" href="_images/k-fold-scheme.png"><img alt="_images/k-fold-scheme.png" class="align-center" src="_images/k-fold-scheme.png" style="width: 600px;" /></a>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>The CV+ algorithm goes as follows.
Let <span class="math notranslate nohighlight">\(n = |D_{train}|\)</span>, and let <span class="math notranslate nohighlight">\(D_{train}\)</span> be partitioned disjointly into the sets <span class="math notranslate nohighlight">\(S_1, S_2, \dots, S_K\)</span>.
Each training point <span class="math notranslate nohighlight">\((X_i,Y_i) \in D_{train}\)</span> belongs to one partition, noted as <span class="math notranslate nohighlight">\(S_{k(i)}\)</span>.</p>
<p>At training, we fit and store in memory <span class="math notranslate nohighlight">\(K\)</span> models, referred to as <span class="math notranslate nohighlight">\(\widehat{f}_{-S_{K}}\)</span> to indicate that it was fitted using all data points <em>except</em> those in partition <span class="math notranslate nohighlight">\(S_{K}\)</span>.
Then, the conformalization step boils down to computing, for each <span class="math notranslate nohighlight">\((X_i,Y_i) \in D_{train}\)</span>, the score:</p>
<div class="math notranslate nohighlight">
\[R_i^{CV} = | Y_i - \widehat{f}_{-S_{k(i)}}(X_i)|, i=1, \dots, n\]</div>
<p>If <span class="math notranslate nohighlight">\(K = n\)</span>, we obtain the <em>Jackknife+</em>, <strong>leave-one-out</strong> version of the algorithm.</p>
<p><strong>Inference</strong></p>
<p>The lower and upper bounds of the prediction interval are given by:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Compute <span class="math notranslate nohighlight">\(\bar{R}_{L} = \{ \widehat{f}_{-S_{k(i)}}(X_{new}) - R_i^{CV} \}_{i=1}^{n}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\widehat{L}_{\alpha}(X_{new}) = \lfloor \alpha (n+1) \rfloor\)</span>-th smallest value in <span class="math notranslate nohighlight">\(\bar{R}_{L}\)</span> (lower bound)</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(\bar{R}_{U} = \{ \widehat{f}_{-S_{k(i)}}(X_{new}) + R_i^{CV} \}_{i=1}^{n}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\widehat{U}_{\alpha}(X_{new}) = \lceil (1-\alpha) (n+1) \rceil\)</span>-th smallest value in <span class="math notranslate nohighlight">\(\bar{R}_{U}\)</span> (upper bound)</p></li>
</ol>
</div></blockquote>
<div class="math notranslate nohighlight">
\[\widehat{C}_{\alpha}(X_{new}) = \Big[ \widehat{L}_{\alpha}(X_{new}), \widehat{U}_{\alpha}(X_{new}) \Big].\]</div>
</section>
<section id="ensemble-batch-prediction-intervals-enbpi">
<h3>Ensemble Batch Prediction Intervals (EnbPI)<a class="headerlink" href="#ensemble-batch-prediction-intervals-enbpi" title="Permalink to this heading"></a></h3>
<p id="theory-enbpi">TBC</p>
</section>
</section>
<section id="conformal-classification">
<h2>Conformal Classification<a class="headerlink" href="#conformal-classification" title="Permalink to this heading"></a></h2>
<section id="adaptive-prediction-sets-aps">
<h3>Adaptive Prediction Sets (APS)<a class="headerlink" href="#adaptive-prediction-sets-aps" title="Permalink to this heading"></a></h3>
<span class="target" id="theory-aps"></span><p>TBC</p>
</section>
<section id="regularized-adaptive-prediction-sets-raps">
<h3>Regularized Adaptive Prediction Sets (RAPS)<a class="headerlink" href="#regularized-adaptive-prediction-sets-raps" title="Permalink to this heading"></a></h3>
<span class="target" id="theory-raps"></span><p>TBC</p>
</section>
</section>
<section id="conformal-anomaly-detection">
<h2>Conformal Anomaly Detection<a class="headerlink" href="#conformal-anomaly-detection" title="Permalink to this heading"></a></h2>
<p>TBC</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h2>
<div role="list" class="citation-list">
<div class="citation" id="angelopoulos2022" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">Angelopoulos2022</a><span class="fn-bracket">]</span></span>
<p>Angelopoulos, A.N. and Bates, S., (2021). A gentle introduction to conformal prediction and distribution-free uncertainty quantification. arXiv preprint arXiv:2107.07511. https://arxiv.org/abs/2107.07511</p>
</div>
<div class="citation" id="barber2021" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">Barber2021</a><span class="fn-bracket">]</span></span>
<p>Barber, R. F., Candes, E. J., Ramdas, A., &amp; Tibshirani, R. J. (2021). Predictive inference with the jackknife+. Ann. Statist. 49 (1) 486 - 507, February 2021. <a class="reference external" href="https://arxiv.org/abs/1905.02928">https://arxiv.org/abs/1905.02928</a></p>
</div>
<div class="citation" id="lei2018" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">Lei2018</a><span class="fn-bracket">]</span></span>
<p>Lei, J., G’Sell, M., Rinaldo, A., Tibshirani, R.J. and Wasserman, L., (2018). Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113(523), pp.1094-1111. <a class="reference external" href="https://arxiv.org/abs/1604.04173">https://arxiv.org/abs/1604.04173</a></p>
</div>
<div class="citation" id="papadopoulos2002" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">Papadopoulos2002</a><span class="fn-bracket">]</span></span>
<p>Papadopoulos, H., Proedrou, K., Vovk, V. and Gammerman, A., (2002). Inductive confidence machines for regression. In Proceedings of ECML 2002, Springer. <a class="reference external" href="https://link.springer.com/chapter/10.1007/3-540-36755-1_29">https://link.springer.com/chapter/10.1007/3-540-36755-1_29</a></p>
</div>
<div class="citation" id="papadopoulos2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">Papadopoulos2008</a><span class="fn-bracket">]</span></span>
<p>Papadopoulos, H., Gammerman, A. and Vovk, V., (2008), February. Normalized nonconformity measures for regression conformal prediction. In Proceedings of the IASTED International Conference on Artificial Intelligence and Applications (AIA 2008) (pp. 64-69).</p>
</div>
<div class="citation" id="romano2019" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">Romano2019</a><span class="fn-bracket">]</span></span>
<p>Romano, Y., Patterson, E. and Candes, E., (2019). Conformalized quantile regression. In Proceedings of NeurIPS, 32. <a class="reference external" href="https://arxiv.org/abs/1905.03222">https://arxiv.org/abs/1905.03222</a></p>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plotting.html" class="btn btn-neutral float-left" title="🖼️ Plotting" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, IRT Antoine de Saint Exupéry - All rights reserved. DEEL is a research program operated by IVADO, IRT Saint Exupéry, CRIAQ and ANITI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>