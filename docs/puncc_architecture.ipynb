{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3df483a",
   "metadata": {},
   "source": [
    "# ðŸ’» Welcome to the presentation of *puncc*'s architecture\n",
    "\n",
    "*Puncc* enables a turnkey solution and a fully customized approach to conformal prediction. It is as simple as calling the conformal prediction procedures in `deel.puncc.regression` or `deel.puncc.classification`.\n",
    "\n",
    "The currently implemented conformal regression procedures are the following:\n",
    "* `deel.puncc.regression.SplitCP`: Split Conformal Prediction\n",
    "* `deel.puncc.regression.LocallyAdaptiveCP`: Locally Adaptive Conformal Prediction\n",
    "* `deel.puncc.regression.CQR`: Conformalized Quantile Regression\n",
    "* `deel.puncc.regression.CvPlus`: CV + (cross-validation)\n",
    "* `deel.puncc.regression.EnbPI`: Ensemble Batch Prediction Intervals method\n",
    "* `deel.puncc.regression.aEnbPI`: locally adaptive Ensemble Batch Prediction Intervals method\n",
    "\n",
    "The currently implemented conformal classification procedures are the following:\n",
    "* `deel.puncc.classification.APS`: Adaptive Prediction Sets. \n",
    "* `deel.puncc.classification.RAPS`: Regularized Adaptive Prediction Sets. APS is a special case where regularization term is nulled ($\\lambda = 0$).\n",
    "\n",
    "Each of these procedures conformalize point-based or interval-based models that are wrapped in a predictor and passed as argument to the constructor. Wrapping the models in a predictor (`deel.puncc.api.prediction`) enables to work with several ML/DL libraries and data structures.\n",
    "\n",
    "The **API** offers more flexibility into defining conformal prediction procedures. Let's say we want to fit/calibrate a neural-network interval-estimator with a cross-validation plan; or that we want to experiment different user-defined nonconformity scores. In such cases and others, the user can fully construct their approaches using the proposed **Predictor-Calibrator-Splitter** paradigm. It boils down to assembling into `puncc.api.conformalization.ConformalPredictor`:\n",
    "1) a predictor\n",
    "2) A calibrator defining a nonconformity score and a procedure to construct/calibrate the prediction sets\n",
    "3) A splitter defining the strategy of data assignement into fitting and calibration sets\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "    <img src=\"assets/puncc_architecture.png\"/>\n",
    "</figure>\n",
    "\n",
    "**Table of contents**\n",
    "\n",
    "- [Conformal Predictor](#conformal-predictor)\n",
    "- [Predictor](#predictor)\n",
    "- [Calibrator](#calibrator)\n",
    "- [Splitter](#splitter)\n",
    "\n",
    "\n",
    "**Links**\n",
    "- [<img src=\"https://github.githubassets.com/images/icons/emoji/octocat.png\" width=20> Github](https://github.com/deel-ai/puncc)\n",
    "- [ðŸ“˜ Documentation](https://deel-ai.github.io/puncc/index.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86e74031",
   "metadata": {},
   "source": [
    "## Conformal Predictor <a class=\"anchor\" id=\"conformal-predictor\"></a>  \n",
    "\n",
    "`deel.puncc.api.conformalization.ConformalPredictor` is the canvas of conformal prediction procedures.\n",
    "An object instance is constructed by, as we will explain later, a **predictor**, a **calibrator** and a **splitter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn import linear_model\n",
    "from deel.puncc.api.conformalization import ConformalPredictor\n",
    "from deel.puncc.api.prediction import BasePredictor\n",
    "from deel.puncc.api.calibration import BaseCalibrator\n",
    "from deel.puncc.api.splitting import KFoldSplitter\n",
    "\n",
    "# Regression linear model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Definition of a predictor (This will be explained later)\n",
    "my_predictor = BasePredictor(model) # Predictor\n",
    "\n",
    "# Definition of a calibrator, built for a given nonconformity scores and a\n",
    "# procedure to build the prediction sets\n",
    "\n",
    "## Definition of a custom nonconformity scores function.\n",
    "## Alternatively, several ready-to-use nonconf scores are provided in\n",
    "## the module deel.puncc.nonconformity_scores (more on this later)\n",
    "def my_ncf(y_pred, y_true):\n",
    "    return np.abs(y_pred-y_true)\n",
    "\n",
    "## Definition of a custom function to build prediction sets.\n",
    "## Alternatively, several ready-to-use procedure are provided in\n",
    "## the module deel.puncc.prediction_sets (more on this later)\n",
    "def my_psf(y_pred, nonconf_scores_quantile):\n",
    "    y_lower = y_pred - nonconf_scores_quantile\n",
    "    y_upper = y_pred + nonconf_scores_quantile\n",
    "    return y_lower, y_upper\n",
    "\n",
    "## Calibrator construction\n",
    "my_calibrator = BaseCalibrator(nonconf_score_func=my_ncf,\n",
    "                                pred_set_func=my_psf) # Calibrator\n",
    "\n",
    "# Definition of a K-fold splitter that produces 20 folds of fit/calibration\n",
    "kfold_splitter = KFoldSplitter(K=20, random_state=42) # Splitter\n",
    "\n",
    "# Conformal prediction canvas\n",
    "conformal_predictor = ConformalPredictor(predictor=my_predictor,\n",
    "                                        calibrator=my_calibrator,\n",
    "                                        splitter=kfold_splitter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56bfc437",
   "metadata": {},
   "source": [
    "`deel.puncc.api.conformalization.ConformalPredictor` implements two methods:\n",
    "\n",
    "* A `fit` method that fits the predictor model and computes nonconformity scores accodingly to the calibrator and to the data split strategy provided by the splitter\n",
    "* And a `predict` method that estimates for new samples the point predictions and prediction intervals [y_pred_lower, y_pred_upper], w.r.t a chosen error (significance) level $\\alpha$\n",
    "\n",
    "The full code snippet of the previous CVplus-like procedure with a randomly generated dataset is provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from deel.puncc.api.conformalization import ConformalPredictor\n",
    "from deel.puncc.api.prediction import BasePredictor\n",
    "from deel.puncc.api.calibration import BaseCalibrator\n",
    "from deel.puncc.api.splitting import KFoldSplitter\n",
    "from deel.puncc.plotting import plot_prediction_intervals\n",
    "from deel.puncc import metrics\n",
    "\n",
    "# Data\n",
    "## Generate a random regression problem\n",
    "X, y = make_regression(n_samples=1000, n_features=4, n_informative=2,\n",
    "                        random_state=0, noise=10, shuffle=False)\n",
    "\n",
    "## Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.2, random_state=0\n",
    ")\n",
    "\n",
    "# Regression linear model\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Definition of a predictor (This will be explained later)\n",
    "my_predictor = BasePredictor(model) # Predictor\n",
    "\n",
    "# Definition of a calibrator, built for a given nonconformity scores and a\n",
    "# procedure to build the prediction sets\n",
    "\n",
    "## Definition of a custom nonconformity scores function.\n",
    "## Alternatively, several ready-to-use nonconf scores are provided in\n",
    "## the module deel.puncc.nonconformity_scores (more on this later)\n",
    "def my_ncf(y_pred, y_true):\n",
    "    return np.abs(y_pred-y_true)\n",
    "\n",
    "## Definition of a custom function to build prediction sets.\n",
    "## Alternatively, several ready-to-use procedure are provided in\n",
    "## the module deel.puncc.prediction_sets (more on this later)\n",
    "def my_psf(y_pred, nonconf_scores_quantile):\n",
    "    y_lower = y_pred - nonconf_scores_quantile\n",
    "    y_upper = y_pred + nonconf_scores_quantile\n",
    "    return y_lower, y_upper\n",
    "\n",
    "## Calibrator construction\n",
    "my_calibrator = BaseCalibrator(nonconf_score_func=my_ncf,\n",
    "                                pred_set_func=my_psf) # Calibrator\n",
    "\n",
    "# Definition of a K-fold splitter that produces 20 folds of fit/calibration\n",
    "kfold_splitter = KFoldSplitter(K=20, random_state=42) # Splitter\n",
    "\n",
    "# Conformal prediction canvas\n",
    "conformal_predictor = ConformalPredictor(predictor=my_predictor,\n",
    "                                        calibrator=my_calibrator,\n",
    "                                        splitter=kfold_splitter)\n",
    "conformal_predictor.fit(X_train, y_train)\n",
    "y_pred, y_pred_lower, y_pred_upper = conformal_predictor.predict(X_test, alpha=.1)\n",
    "\n",
    "# Compute empirical marginal coverage and average width of the prediction intervals\n",
    "coverage = metrics.regression_mean_coverage(y_test, y_pred_lower, y_pred_upper)\n",
    "width = metrics.regression_sharpness(y_pred_lower=y_pred_lower,\n",
    "                                    y_pred_upper=y_pred_upper)\n",
    "print(f\"Marginal coverage: {coverage:.2f}\")\n",
    "print(f\"Average width: {width:.2f}\")\n",
    "\n",
    "# Figure of the prediction bands\n",
    "ax = plot_prediction_intervals(\n",
    "        X = X_test[:,0],\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "        y_pred_lower=y_pred_lower,\n",
    "        y_pred_upper=y_pred_upper,\n",
    "        sort_X=True,\n",
    "        size=(10, 6),\n",
    "        loc=\"upper left\")\n",
    "\n",
    "_ = ax.set_xlabel(\"Dummy X\")\n",
    "_ = ax.set_ylabel(\"Dummy Y\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "112f2205",
   "metadata": {},
   "source": [
    "## Predictor <a class=\"anchor\" id=\"predictor\"></a>  \n",
    "\n",
    "The `deel.puncc.api.prediction.BasePredictor` and `deel.puncc.api.prediction.DualPredictor` classes are wrappers of ML/DL models\n",
    "that aims to expose a standardized interface and guarantee compliance with the `puncc`'s framework.\n",
    "The predictors have to implement:\n",
    "\n",
    "* a `fit` method used to train the model. It takes as arguments two iterables X, Y (collection of data such as ndarray and tensors) and any additional configuration of the underlying model (e.g., random seed).\n",
    "* a `predict` method used to predict targets for a given iterable X. It takes as arguments an iterable X and any additional configuration of the underlying model (e.g., batch size).\n",
    "* a `copy` method that returns a copy of the predictor (useful in cross validation for example). It has to deepcopy the underlying model.\n",
    "\n",
    "The constructor of `deel.puncc.api.prediction.BasePredictor` takes in the model to be wrapped, a flag to inform if the model is already trained\n",
    "and compilation keyword arguments if the underlying model needs to be compiled (such as in TensorFlow or PyTorch).\n",
    "\n",
    "The constructor of `deel.puncc.api.prediction.DualPredictor` is conceptually similar but take as arguments a list of two models, a list of two trained flags and a list of two compilation kwargs.\n",
    "Such predictor is useful when the calibration relies of several models (such as upper and lower quantiles in CQR).\n",
    "Note that the output `y_pred` of the `predict` method are a collection of couples, where the first (resp. second) axis is associated to the output of the first (resp. second) model.\n",
    "Specifically, `deel.puncc.api.prediction.MeanVarPredictor` is a subclass of `deel.puncc.api.prediction.DualPredictor` that\n",
    "trains the first model on the data and the second one to predict the absolute error of the former model.\n",
    "\n",
    "These three predictor classes cover plenty of use case in conformal prediction.\n",
    "But if you have a special need, you can subclass `deel.puncc.api.prediction.BasePredictor` or `deel.puncc.api.prediction.DualPredictor` or\n",
    "even create a predictor from scratch.\n",
    "\n",
    "Here is a example of situation where you need to define your own predictor:\n",
    "you have a classification problem and you build a `RandomForestClassifier`\n",
    "from sklearn. The procedure `RAPS` to conformalize the classifier requires\n",
    "a `predict` method that outputs the estimated probabily of each class. This is not the case\n",
    "as `RandomForestClassifier.predict` returns only the most likely class. In this case,\n",
    "we need to create a predictor in which we redefine the `predict` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deel.puncc.api.prediction import BasePredictor\n",
    "\n",
    "# Create rf classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Create a wrapper of the random forest model to redefine its predict method\n",
    "# into logits predictions. Make sure to subclass BasePredictor.\n",
    "# Note that we needed to build a new wrapper (over BasePredictor) only because\n",
    "# the predict(.) method of RandomForestClassifier does not predict logits.\n",
    "# Otherwise, it is enough to use BasePredictor (e.g., neural network with softmax).\n",
    "class RFPredictor(BasePredictor):\n",
    "    def predict(self, X, **kwargs):\n",
    "        return self.model.predict_proba(X, **kwargs)\n",
    "\n",
    "# Wrap model in the newly created RFPredictor\n",
    "rf_predictor = RFPredictor(rf_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74dd0bbc",
   "metadata": {},
   "source": [
    "## Calibrator <a class=\"anchor\" id=\"calibrator\"></a>  \n",
    "\n",
    "The calibrator provides a structure to estimate the nonconformity scores\n",
    "on the calibration set and to compute the prediction sets. At the constructor `deel.puncc.api.calibration.BaseCalibrator`,\n",
    "one decides which nonconformity score and prediction set functions to use.\n",
    "Then, the calibrator instance computes **nonconformity scores** (e.g., absolute difference) by calling\n",
    "`deel.puncc.api.calibration.Calibrator.fit` on the calibration dataset. Based on the estimated quantiles of nonconformity scores,\n",
    "the method `deel.puncc.api.calibration.BaseCalibrator.calibrate` enables to **construct** and/or **calibrate** prediction sets.\n",
    "\n",
    "For example, the `BaseCalibrator` in the split conformal prediction procedure\n",
    "uses the absolute difference as nonconformity score and prediction sets\n",
    "are built as constant intervals. These two functions are already provided in\n",
    "`deel.puncc.api.nonconformity_scores.absolute_difference` and `deel.puncc.api.prediction_sets.constant_interval`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72983b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.puncc.api.calibration import BaseCalibrator\n",
    "from deel.puncc.api import nonconformity_scores\n",
    "from deel.puncc.api import prediction_sets\n",
    "\n",
    "## Calibrator construction\n",
    "my_calibrator = BaseCalibrator(nonconf_score_func=nonconformity_scores.absolute_difference,\n",
    "                                pred_set_func=prediction_sets.constant_interval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d15a6be2",
   "metadata": {},
   "source": [
    "Alternatively, one can define custom functions and pass them as arguments to the calibrator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9866d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.puncc.api.calibration import BaseCalibrator\n",
    "\n",
    "## Definition of a custom nonconformity scores function.\n",
    "## Alternatively, several ready-to-use nonconf scores are provided in\n",
    "## the module deel.puncc.nonconformity_scores\n",
    "def my_ncf(y_pred, y_true):\n",
    "    return np.abs(y_pred-y_true)\n",
    "\n",
    "## Definition of a custom function to build prediction sets.\n",
    "## Alternatively, several ready-to-use procedure are provided in\n",
    "## the module deel.puncc.prediction_sets\n",
    "def my_psf(y_pred, nonconf_scores_quantile):\n",
    "    y_lower = y_pred - nonconf_scores_quantile\n",
    "    y_upper = y_pred + nonconf_scores_quantile\n",
    "    return y_lower, y_upper\n",
    "\n",
    "## Calibrator construction\n",
    "my_calibrator = BaseCalibrator(nonconf_score_func=my_ncf, pred_set_func=my_psf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74cab56f",
   "metadata": {},
   "source": [
    "## Splitter <a class=\"anchor\" id=\"splitter\"></a>  \n",
    "\n",
    "In conformal prediction, the assignement of data into fit and calibration sets is motivated by two criteria:\n",
    "data availability and computational resources. If quality data is abundant,\n",
    "we can split the training samples into disjoint subsets $D_{fit}$ and $D_{calib}$.\n",
    "When data is scarce, a cross-validation strategy is preferred but is more\n",
    "ressource-consuming as different models are trained and nonconformity scores\n",
    "are computed for different disjoint folds.\n",
    "\n",
    "The two plans are implemented in `deel.puncc.api.splitting` module,\n",
    "and are agnostic to the data structure (which can be ndarrays, tensors and dataframes):\n",
    "\n",
    "- `deel.puncc.api.splitting.RandomSplitter`: random assignement of samples in $D_{fit}$ and $D_{calib}$\n",
    "- `deel.puncc.api.splitting.KFoldSplitter`: random assignement of samples into K disjoint folds. Note that if K equals the size of training set, the split is identified with the leave-one-out strategy\n",
    "\n",
    "Additionnaly, if the user already implemted a split plan, the obtained data asignement\n",
    "is wrapped in `deel.puncc.api.splitting.IdSplitter` to produce iterables.\n",
    "\n",
    "These methods produce **iterables** that are used by the `ConformalPredictor` instance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "punc-user-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
